# MNIST Neural Network from Scratch (Kaggle Notebook)

A simple, fullyâ€‘connected 2â€‘layer neural network built from scratch using NumPy â€” developed and trained entirely in a Kaggle Notebook to classify handwritten digits from the MNIST dataset.

## ðŸ“Œ Overview

- **No deep learning libraries** â€” built with pure NumPy
- Implements forward propagation, backpropagation, and gradient descent
- Utilizes ReLU activation in the hidden layer and Softmax in the output layer
- Trained on the MNIST dataset (from Kaggle)

## ðŸ”§ Environment

- âœ… Run inside [Kaggle Notebooks](https://www.kaggle.com/code)
- ðŸ“¦ Dependencies:
  - Python 3.x
  - NumPy
  - Pandas
  - Matplotlib (optional, for visualizations)

## ðŸ—ƒ Dataset

- MNIST Digit Recognizer dataset from Kaggle:
  - ðŸ“¥ [https://www.kaggle.com/datasets/animatronbot/mnist-digit-recognizer](https://www.kaggle.com/datasets/animatronbot/mnist-digit-recognizer)

## ðŸ§  Neural Network Architecture

- **Input Layer**: 784 neurons (28Ã—28 pixel images)
- **Hidden Layer**: 10 neurons, ReLU activation
- **Output Layer**: 10 neurons (digits 0â€“9), Softmax activation
